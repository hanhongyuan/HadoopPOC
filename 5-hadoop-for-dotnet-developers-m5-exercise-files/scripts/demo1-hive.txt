
-- create a table over the postcodes data, mapping all fields as strings
-- and surfacing all files in the /input folder in HDFS:
CREATE EXTERNAL TABLE Postcodes
(
	Postcode1 STRING, 
	Postcode2 STRING, 
	Postcode3 STRING, 
	DateIntroduced STRING, 
	UserType STRING, 
	Easting STRING, 
	Northing STRING, 
	PositionalQuality STRING, 
	CountyCode STRING, 
	CountyName STRING, 
	LocalAuthorityCode STRING, 
	LocalAuthorityName STRING, 
	WardCode STRING, 
	WardName STRING, 
	CountryCode STRING, 
	CountryName STRING, 
	RegionCode STRING, 
	RegionName STRING, 
	ParliamentaryConstituencyCode STRING, 
	ParliamentaryConstituencyName STRING, 
	EuropeanElectoralRegionCode STRING, 
	EuropeanElectoralRegionName STRING, 
	PrimaryCareTrustCode STRING, 
	PrimaryCareTrustName STRING, 
	LowerSuperOutputAreaCode STRING, 
	LowerSuperOutputAreaName STRING, 
	MiddleSuperOutputAreaCode STRING, 
	MiddleSuperOutputAreaName STRING, 
	OutputAreaClassificationCode STRING, 
	OutputAreaClassificationName STRING, 
	Longitude STRING, 
	Latitude STRING, 
	SpatialAccuracy STRING, 
	LastUploaded STRING, 
	Location STRING, 
	SocrataID STRING
)
--ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
STORED AS TEXTFILE
LOCATION '/input'
TBLPROPERTIES ("skip.header.line.count"="1");


-- fetch the first 10 rows:
SELECT * FROM Postcodes LIMIT 10;

-- show counts by classification:
SELECT OutputAreaClassificationName, COUNT(1)
FROM Postcodes
GROUP BY OutputAreaClassificationName;


-- fetch first 10 rows and transform the data using .NET Core app:
ADD FILE /dotnetcore;
SELECT TRANSFORM (OutputAreaClassificationCode, OutputAreaClassificationName)
USING 'dotnet dotnetcore/hiveudf.dll' AS (FormattedClassification STRING)
FROM Postcodes
LIMIT 10;





